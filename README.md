# Privacy-Preserving-Machine-Learning

## Problem Description

· **System:** Electronic Health Record (EHR) systems store patients' medical data, including diagnoses, treatments, and personal information. Machine learning algorithms can analyze EHR data to improve patient care, but privacy concerns are a major obstacle.

· **Assets:** The privacy of patients' personal and medical information, which can be valuable for unauthorized uses (e.g., identity theft or blackmail).

· **Attackers:** Potential attackers include cybercriminals, hackers, or other unauthorized third parties.

· **Vulnerabilities:** Data breaches, insecure communication channels, or insufficient access controls.

· **Threats:** Unauthorized access, data leakage, or misuse of sensitive information.

· **Risks:** The risks are significant given the sensitive nature of medical data, the potential harm to patients, and possible legal repercussions for healthcare providers.


## Proposed Solution
**Category**

· Our solution falls into secure multi-party computation (SMPC), differential privacy, and/or fully homomorphic encryption (FHE).

· We propose a privacy-preserving machine learning framework for EHR systems, which allows healthcare providers to collaboratively train and evaluate machine learning models without sharing raw patient data.

** Expected Benefits**

· Enhanced data privacy and security for patients

· Compliance with privacy regulations (e.g., HIPAA, GDPR)
